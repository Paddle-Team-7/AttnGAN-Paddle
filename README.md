# AttnGAN

Paddle implementation for reproducing AttnGAN results in the paper [AttnGAN: Fine-Grained Text to Image Generation
with Attentional Generative Adversarial Networks](http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_AttnGAN_Fine-Grained_Text_CVPR_2018_paper.pdf) by Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, Xiaodong He. (This work was performed when Tao was an intern with Microsoft Research). 

<img src="framework.png" width="900px" height="350px"/>


### Dependencies
python 3.7

Paddle

scikit-image


**Reproduce IS**

| | Raw Paper | Reprod |
|--|--|--|
|Inception Score| 25.89 | 4.33 |

**Data**

1. Download our preprocessed metadata for [coco](https://drive.google.com/open?id=1rSnbIGNDGZeHlsUlLdahj0RJ9oo6lgH9) and save them to `data/`
2. Download [coco](http://cocodataset.org/#download) dataset and extract the images to `data/coco/`



**Training**
- Pre-train DAMSM models:
  - For coco dataset: `python pretrain_DAMSM.py --cfg cfg/DAMSM/coco.yml`
 
- Train AttnGAN models:
  - For coco dataset: `python main.py --cfg cfg/coco_attn2.yml`

- `*.yml` files are example configuration files for training/evaluation our models.



**Pretrained Model**
- [DAMSM for coco](https://pan.baidu.com/s/1lM_v3ROm-RXsV1FVh4Trfw)(haqh). Download and save it to `DAMSMencoders/`
- [AttnGAN for coco](https://pan.baidu.com/s/1lM_v3ROm-RXsV1FVh4Trfw)(haqh). Download and save it to `models/`


**Sampling**
- Run `python main.py --cfg cfg/eval_coco.yml` to generate examples from captions in files listed in "./data/coco/example_filenames.txt". Results are saved to `DAMSMencoders/`. 


**Validation**
- To generate images for all captions in the validation dataset, change B_VALIDATION to True in the eval_coco.yml. and then run `python main.py --cfg cfg/eval_coco.yml`
- Run `python inception_score.py` to compute inception score. Remember to change the data path in scripts.


**Examples generated by AttnGAN**

 coco example              |  coco example
:-------------------------:|:-------------------------:
![](https://github.com/Paddle-Team-7/AttnGAN-Paddle/blob/master/COCO_val2014_000000002985_s-1.png)  |  ![](https://github.com/Paddle-Team-7/AttnGAN-Paddle/blob/master/COCO_val2014_000000003794_s-1.png)

